AWSTemplateFormatVersion: '2010-09-09'
Resources:
  NoteDynamoDBTable:
    Type: 'AWS::DynamoDB::Table'
    Properties:
      BillingMode: PAY_PER_REQUEST
      AttributeDefinitions:
        - AttributeName: CreatedAt
          AttributeType: S
        - AttributeName: Name
          AttributeType: S
      KeySchema:
        - AttributeName: CreatedAt
          KeyType: HASH
        - AttributeName: Name
          KeyType: RANGE

  NoteS3Bucket:
    Type: 'AWS::S3::Bucket'
  

  CULambdaFunction:
    Type: 'AWS::Lambda::Function'
    Properties:
      Runtime: python3.12
      Handler: index.lambda_handler 
      Role: !GetAtt MyLambdaExecutionRole.Arn
      Environment:
        Variables:
          DYNAMODB_TABLE_NAME: !Ref NoteDynamoDBTable
          S3_BUCKET_NAME: !Ref NoteS3Bucket
      Code:
        ZipFile: |
          import json
          import os
          import boto3
          from botocore.exceptions import ClientError
          from datetime import datetime
          import uuid  # for generating unique NoteID

          # Get the DynamoDB table name and S3 bucket name from environment variables
          table_name = os.environ.get('DYNAMODB_TABLE_NAME')
          s3_bucket_name = os.environ.get('S3_BUCKET_NAME')

          # Create DynamoDB and S3 resources
          dynamodb = boto3.resource('dynamodb')
          table = dynamodb.Table(table_name)
          s3 = boto3.client('s3')

          def lambda_handler(event, context):
              # Extract values directly from the query string parameters
              name = event.get('queryStringParameters', {}).get('Name')
              content = event.get('queryStringParameters', {}).get('Content')

              # Set date timestamp without time
              now = datetime.utcnow().date().isoformat()

              # Generate a unique NoteID
              note_id = str(uuid.uuid4())

              try:
                  # Use the same S3 object key for updates
                  s3_object_key = f'notes/{name}.txt'  # Use a meaningful object key based on the note name

                  # Upload or overwrite content in S3
                  s3.put_object(Body=content, Bucket=s3_bucket_name, Key=s3_object_key)

                  # Update metadata in DynamoDB
                  response = table.put_item(
                      Item={
                          'NoteID': note_id,
                          'CreatedAt': now,
                          'Name': name,
                          'UpdatedAt': datetime.utcnow().isoformat(),
                      }
                  )

                  return {
                      'statusCode': 200,
                      'body': json.dumps({'message': 'Note saved successfully'})
                  }

              except ClientError as e:
                  error_message = str(e)
                  print(f"Error: {error_message}")
                  return {
                      'statusCode': 500,
                      'body': json.dumps({'error': error_message})
                  }

              except Exception as e:
                  error_message = str(e)
                  print(f"Unexpected error: {error_message}")
                  return {
                      'statusCode': 500,
                      'body': json.dumps({'error': 'Internal Server Error'})
                  }
      Timeout: 30

  READLambdaFunction:
    Type: 'AWS::Lambda::Function'
    Properties:
      Runtime: python3.12
      Handler: index.lambda_handler 
      Role: !GetAtt MyLambdaExecutionRole.Arn
      Environment:
        Variables:
          DYNAMODB_TABLE_NAME: !Ref NoteDynamoDBTable
          S3_BUCKET_NAME: !Ref NoteS3Bucket
      Code:
        ZipFile: |
          import json
          import os
          import boto3
          from botocore.exceptions import ClientError

          # Get the DynamoDB table name and S3 bucket name from environment variables
          table_name = os.environ.get('DYNAMODB_TABLE_NAME')
          s3_bucket_name = os.environ.get('S3_BUCKET_NAME')

          # Create DynamoDB and S3 resources
          dynamodb = boto3.resource('dynamodb')
          table = dynamodb.Table(table_name)
          s3 = boto3.client('s3')

          def lambda_handler(event, context):
              # Extract values directly from the event body
              created_at = event.get('queryStringParameters', {}).get('CreatedAt')
              name = event.get('queryStringParameters', {}).get('Name')

              try:
                  # Retrieve metadata from DynamoDB
                  response = table.get_item(
                      Key={
                          'CreatedAt': created_at,
                          'Name': name
                      }
                  )

                  # Check if the item was found
                  if 'Item' in response:
                      item = response['Item']

                      # Fetch note content from S3
                      s3_object_key = f'notes/{name}.txt'  # Adjust the format as needed
                      s3_response = s3.get_object(Bucket=s3_bucket_name, Key=s3_object_key)
                      note_content = s3_response['Body'].read().decode('utf-8')

                      # Include note content in the response
                      item['Content'] = note_content

                      return {
                          'statusCode': 200,
                          'body': json.dumps({'message': 'Item found', 'item': item})
                      }
                  else:
                      return {
                          'statusCode': 404,
                          'body': json.dumps({'error': 'Item not found'})
                      }

              except ClientError as e:
                  error_message = str(e)
                  print(f"Error: {error_message}")
                  return {
                      'statusCode': 500,
                      'body': json.dumps({'error': error_message})
                  }

              except Exception as e:
                  error_message = str(e)
                  print(f"Unexpected error: {error_message}")
                  return {
                      'statusCode': 500,
                      'body': json.dumps({'error': 'Internal Server Error'})
                  }
      Timeout: 30

  DELETELambdaFunction:
    Type: 'AWS::Lambda::Function'
    Properties:
      Runtime: python3.12
      Handler: index.lambda_handler 
      Role: !GetAtt MyLambdaExecutionRole.Arn
      Environment:
        Variables:
          DYNAMODB_TABLE_NAME: !Ref NoteDynamoDBTable
          S3_BUCKET_NAME: !Ref NoteS3Bucket
      Code:
        ZipFile: |
          import json
          import os
          import boto3
          from botocore.exceptions import ClientError

          # Get the DynamoDB table name and S3 bucket name from environment variables
          table_name = os.environ.get('DYNAMODB_TABLE_NAME')
          s3_bucket_name = os.environ.get('S3_BUCKET_NAME')

          # Create DynamoDB and S3 resources
          dynamodb = boto3.resource('dynamodb')
          table = dynamodb.Table(table_name)
          s3 = boto3.client('s3')

          def lambda_handler(event, context):
              # Extract values directly from the query string parameters
              created_at = event.get('queryStringParameters', {}).get('CreatedAt')
              name = event.get('queryStringParameters', {}).get('Name')

              try:
                  # Retrieve metadata from DynamoDB
                  response = table.get_item(
                      Key={
                          'CreatedAt': created_at,
                          'Name': name
                      }
                  )

                  # Check if the item was found
                  if 'Item' in response:
                      item = response['Item']

                      # Fetch note content from S3
                      s3_object_key = f'notes/{name}.txt'  # Adjust the format as needed

                      # Delete content from S3
                      s3.delete_object(Bucket=s3_bucket_name, Key=s3_object_key)

                      # Delete metadata from DynamoDB
                      response = table.delete_item(
                          Key={
                              'CreatedAt': created_at,
                              'Name': name
                          }
                      )

                      return {
                          'statusCode': 200,
                          'body': json.dumps({'message': 'Item and associated content deleted successfully'})
                      }
                  else:
                      return {
                          'statusCode': 404,
                          'body': json.dumps({'error': 'Item not found'})
                      }

              except ClientError as e:
                  error_message = str(e)
                  print(f"Error: {error_message}")
                  return {
                      'statusCode': 500,
                      'body': json.dumps({'error': error_message})
                  }

              except Exception as e:
                  error_message = str(e)
                  print(f"Unexpected error: {error_message}")
                  return {
                      'statusCode': 500,
                      'body': json.dumps({'error': 'Internal Server Error'})
                  }
      Timeout: 30

  MyLambdaExecutionRole:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: 'sts:AssumeRole'
      ManagedPolicyArns:
        - 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'
        - 'arn:aws:iam::aws:policy/AmazonDynamoDBFullAccess'
        - 'arn:aws:iam::aws:policy/AmazonS3FullAccess'

  S3BucketDeleteFunction:
    Type: 'AWS::Lambda::Function'
    Properties:
      Runtime: python3.12
      Handler: index.lambda_handler 
      Role: !GetAtt MyLambdaExecutionRole.Arn
      Environment:
        Variables:
          S3_BUCKET_NAME: !Ref NoteS3Bucket
      Code:
        ZipFile: |
          import os
          import boto3

          def lambda_handler(event, context):
              # Get the S3 bucket name from the environment variable
              bucket_name = os.environ.get('S3_BUCKET_NAME')

              if not bucket_name:
                  return {
                      'statusCode': 400,
                      'body': 'S3_BUCKET_NAME environment variable not set'
                  }

              # Create an S3 client
              s3 = boto3.client('s3')

              # List all objects in the bucket
              objects = s3.list_objects_v2(Bucket=bucket_name)

              # If there are objects in the bucket, delete them
              if 'Contents' in objects:
                  for obj in objects['Contents']:
                      s3.delete_object(Bucket=bucket_name, Key=obj['Key'])
              
              return {
                  'statusCode': 200,
                  'body': f'All objects deleted from S3 bucket: {bucket_name}'
              }

      Timeout: 30

  S3BucketDeletionResource:
    Type: Custom::S3BucketDeletion
    DependsOn: S3BucketDeleteFunction
    Properties:
      ServiceToken: !GetAtt S3BucketDeleteFunction.Arn
      S3BucketName: !Ref NoteS3Bucket

  S3BucketPolicy:
    Type: 'AWS::S3::BucketPolicy'
    DependsOn: S3BucketDeletionResource
    Properties:
      Bucket: !Ref NoteS3Bucket
      PolicyDocument:
        Statement:
          - Effect: Allow
            Principal:
              Service: cloudformation.amazonaws.com
            Action: 's3:DeleteBucket'
            Resource: !Sub 'arn:aws:s3:::${NoteS3Bucket}'

 
  